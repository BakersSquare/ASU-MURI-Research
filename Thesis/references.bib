@article{BASHA2020112,
title = {Impact of fully connected layers on performance of convolutional neural networks for image classification},
journal = {Neurocomputing},
volume = {378},
pages = {112-119},
year = {2020},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2019.10.008},
url = {https://www.sciencedirect.com/science/article/pii/S0925231219313803},
author = {S.H. Shabbeer Basha and Shiv Ram Dubey and Viswanath Pulabaigari and Snehasis Mukherjee},
keywords = {Convolutional neural networks, Fully connected layers, Image classification, Shallow vs deep CNNs, Wider vs deeper datasets},
abstract = {The Convolutional Neural Networks (CNNs), in domains like computer vision, mostly reduced the need for handcrafted features due to its ability to learn the problem-specific features from the raw input data. However, the selection of dataset-specific CNN architecture, which mostly performed by either experience or expertise is a time-consuming and error-prone process. To automate the process of learning a CNN architecture, this paper attempts at finding the relationship between Fully Connected (FC) layers with some of the characteristics of the datasets. The CNN architectures, and recently datasets also, are categorized as deep, shallow, wide, etc. This paper tries to formalize these terms along with answering the following questions. (i) What is the impact of deeper/shallow architectures on the performance of the CNN w.r.t. FC layers?, (ii) How the deeper/wider datasets influence the performance of CNN w.r.t. FC layers?, and (iii) Which kind of architecture (deeper/shallower) is better suitable for which kind of (deeper/wider) datasets. To address these findings, we have performed experiments with four CNN architectures having different depths. The experiments are conducted by varying the number of FC layers. We used four widely used datasets including CIFAR-10, CIFAR-100, Tiny ImageNet, and CRCHistoPhenotypes to justify our findings in the context of image classification problem. The source code of this work is available at https://github.com/shabbeersh/Impact-of-FC-layers.}
}

@article{jernelv2020convolutional,
  title={Convolutional neural networks for classification and regression analysis of one-dimensional spectral data},
  author={Jernelv, Ine L and Hjelme, Dag Roar and Matsuura, Yuji and Aksnes, Astrid},
  journal={arXiv preprint arXiv:2005.07530},
  year={2020}
}

@misc{ICESat-2-L4-Product, 
title={ICESat-2 L4 Along-Track Sea Ice Thickness, Version 1}, 
url={https://nsidc.org/data/IS2SITDAT4/versions/1},
DOI={10.5067/JTI5YG3S6VAJ}, 
publisher={NASA National Snow and Ice Data Center Distributed Active Archive Center}, 
author={Petty, A. A., N. Kurtz, R. Kwok, T. Markus, and T. A. Neumann.},
year={2022} 
 }

 @misc{CESat-2-ATL10-Product, 
 title={ATLAS/ICESat-2 L3A Sea Ice Freeboard, Version 6}, 
 url={https://nsidc.org/data/ATL10/versions/6}, 
 DOI={10.5067/ATLAS/ATL10.006}, 
 publisher={National Snow and Ice Data Center}, 
 author={Kwok, R., A. A. Petty, G. Cunningham, T. Markus, D. Hancock, A. Ivanoff, J. Wimert, M. Bagnardi, N. Kurtz, and the ICESat-2 Science Team.}, year={2023} }

 @misc{In-Situ-Dataset, 
 title={On-Ice Arctic Sea Ice Thickness Measurements by Auger, Core, and Electromagnetic Induction, from the Late 1800s Onward, Version 2}, 
 url={https://nsidc.org/data/G10011/versions/2}, 
 DOI={10.7265/wz0k-4p60}, 
 publisher={National Snow and Ice Data Center}, 
 author={Holt, B.}, 
 year={2019} }