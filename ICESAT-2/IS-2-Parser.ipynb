{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Quick visualization of data along a ICESAT2 Track\n",
    "To understand more about the data being input to this script, consider visiting https://nsidc.org/sites/default/files/atl10-v005-userguide_1_0.pdf\n",
    "Code written originally by: Chris Polashenski\n",
    "Refactored, added command line support, and removed sartopy package: John Baker\n",
    "\"\"\"\n",
    "\n",
    "import h5py\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import numpy as np\n",
    "import sys\n",
    "import haversine as hs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_file = \"D:\\\\ICEEYE\\\\Proposal_ID_PP0091278\\\\CS-13801\\\\SLEA_3279211_180312\\\\Baker\\\\Coincident Data\\\\ATL10QL-01_20240119042539_04792201_006_01.h5\"\n",
    "print(in_file)\n",
    "path_parts = in_file.split(\"\\\\\")\n",
    "file_name = path_parts[-1]\n",
    "del path_parts[-1]\n",
    "\n",
    "path_parts.append(file_name[0:-3])\n",
    "out_file = \"C:\\\\Users\\\\John\\\\Documents\\\\git\\\\ASU-MURI-Research\\\\ICESAT-2\\\\full-data.csv\"\n",
    "print(out_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(in_file, mode='r') as file:\n",
    "    print(list(file.keys()))\n",
    "    beam_enum = ['gt1r', 'gt1l', 'gt2r', 'gt2l', 'gt3r', 'gt3l']\n",
    "\n",
    "    df_dict = {\n",
    "        'Beam': [],\n",
    "        \"Lat\": [],\n",
    "        \"Lon\": [],\n",
    "        \"FBH\": [],\n",
    "        \"FBH Confidence\": [],\n",
    "        \"FBH Quality\": [],\n",
    "        \"FBH Uncertainty\": [],\n",
    "        \"Ground Dist(m)\": [],\n",
    "        \"Along Track Dist(m)\": [],\n",
    "        \"RS Index (1-based)\": [],\n",
    "        \"RS Pos\": [],\n",
    "        \"RS Type\": [],\n",
    "        \"RS Height(m)\": [],\n",
    "        \"RS FB Uncertainty(m)\": [],\n",
    "        \"RS Std Dev\": [],\n",
    "        \"RS MSS\": [],\n",
    "        \"Calendar Time\": [],\n",
    "        \"Height Likely Obstructed\": [],\n",
    "        \"Ice Concentration\": [],\n",
    "        \"Ice Height St Dev\": [],\n",
    "        \"Ice Surface Flag\": [],\n",
    "        \"Ice Surface RMS\": [],\n",
    "        \"Ice Surface Height\": [],\n",
    "        \"Ice Surface Conf\": []\n",
    "    }\n",
    "\n",
    "    if \"gt1r/freeboard_beam_segment/beam_freeboard\" in file:\n",
    "        filePathToBeamData = \"freeboard_beam_segment/beam_freeboard\"\n",
    "    else:\n",
    "        filePathToBeamData = \"freeboard_segment\"\n",
    "\n",
    "    if \"gt1r/freeboard_beam_segment/reference_surface_section\" in file:\n",
    "        filePathToReferenceHeights = \"freeboard_beam_segment/reference_surface_section\"\n",
    "    else:\n",
    "        filePathToReferenceHeights = \"reference_surface_section\"\n",
    "\n",
    "    print(filePathToBeamData)\n",
    "    print(filePathToReferenceHeights)\n",
    "\n",
    "    for beam in beam_enum:\n",
    "        print(beam)\n",
    "        beamDataPath = f\"{beam}/{filePathToBeamData}\"\n",
    "        iceDataPath = f\"{beamDataPath}/heights\"\n",
    "        refDataPath = f\"{beam}/{filePathToReferenceHeights}\"\n",
    "        ############################### Store the reference surface data ########################################\n",
    "        # Read in the distance from the reference surface to the equator\n",
    "        refSurfPos = file[f'/{refDataPath}/beam_refsurf_dist_x']\n",
    "        refSurfPos = list(refSurfPos[:])\n",
    "\n",
    "        # Read in the interpolation flag of the reference surface\n",
    "        refSurfType = file[f\"/{refDataPath}/beam_refsurf_interp_flag\"]\n",
    "        refSurfType = list(refSurfType[:])\n",
    "\n",
    "        # Read in the uncertainty propogating to the freeboard, based on the reference surface estimate\n",
    "        refSurfFbUnc = file[f\"/{refDataPath}/beam_fb_unc_refsurf\"]\n",
    "        refSurfFbUnc = list(refSurfFbUnc[:])\n",
    "\n",
    "        # Read in mean sea surface height (the base elevation everything is referring to)\n",
    "        mss = file[f\"/{refDataPath}/beam_refsurf_mss\"]\n",
    "        mss = list(mss[:])\n",
    "\n",
    "        # Read in the inferred ice elevation (the base elevation for the snow is referring to)\n",
    "        refSurfHeight = file[f\"/{refDataPath}/beam_refsurf_height\"]\n",
    "        refSurfHeight = list(refSurfHeight[:])\n",
    "\n",
    "        # Read in the standard deviation of the refsurf height\n",
    "        refSurfStdDev = file[f'/{refDataPath}/beam_refsurf_sigma']\n",
    "        refSurfStdDev = list(refSurfStdDev[:])\n",
    "        #######################################################################\n",
    "        ############################### Store height segment information to look up later ########################################\n",
    "        # Read in whether the reading was likely clear or obstructed\n",
    "        heightSegFlag = file[f'/{iceDataPath}/layer_flag']\n",
    "        heightSegFlag = list(heightSegFlag[:])\n",
    "\n",
    "        # Read in the ice concentration of the point\n",
    "        heightSegIce = file[f\"/{iceDataPath}/ice_conc_ssmi\"]\n",
    "        heightSegIce = list(heightSegIce[:])\n",
    "\n",
    "        # Read in the standard deviation of the ice surface height\n",
    "        heightSegStdDev = file[f\"/{iceDataPath}/height_segment_sigma\"]\n",
    "        heightSegStdDev = list(heightSegStdDev[:])\n",
    "\n",
    "        # Read in the type of surface this height segment is: [sea ice, potential sea ice, new meaning]\n",
    "        heightSegSshFlag = file[f\"/{iceDataPath}/height_segment_ssh_flag\"]\n",
    "        heightSegSshFlag = list(heightSegSshFlag[:])\n",
    "\n",
    "        # Read in the RMS of the inferred height segment from the photon distribution\n",
    "        heightSegRms = file[f\"/{iceDataPath}/height_segment_rms\"]\n",
    "        heightSegRms = list(heightSegRms[:])\n",
    "\n",
    "        # Read in the estimated ice segment height (relative to the tide free MSS)\n",
    "        heightSegHeight = file[f'/{iceDataPath}/height_segment_height']\n",
    "        heightSegHeight = list(heightSegHeight[:])\n",
    "\n",
    "        # Read in the confidence of the ice height segment reading\n",
    "        heightSegConf = file[f'/{iceDataPath}/height_segment_confidence']\n",
    "        heightSegConf = list(heightSegConf[:])\n",
    "        #######################################################################      \n",
    "\n",
    "        # Read in the lat/lon\n",
    "        latitude = file[f'/{beamDataPath}/latitude']\n",
    "        latitude = list(latitude[:])\n",
    "        longitude = file[f'/{beamDataPath}/longitude']\n",
    "        longitude = list(longitude[:])\n",
    "\n",
    "        print(len(latitude), len(longitude))\n",
    "\n",
    "        # Read in the freeboard height\n",
    "        fbHeight = file[f'/{beamDataPath}/beam_fb_height']\n",
    "        fbHeight = list(fbHeight[:])\n",
    "        print(len(fbHeight))\n",
    "\n",
    "        # Read in the fbh confidence\n",
    "        fbConf = file[f'/{beamDataPath}/beam_fb_confidence']\n",
    "        fbConf = list(fbConf[:])\n",
    "        print(len(fbConf))\n",
    "\n",
    "        # Read in the quality flag\n",
    "        fbQuality = file[f\"/{beamDataPath}/beam_fb_quality_flag\"]\n",
    "        fbQuality = list(fbQuality[:])\n",
    "        print(len(fbQuality))\n",
    "\n",
    "        # Read in the total uncertainty from the refSurf + height\n",
    "        fbUnc = file[f\"/{beamDataPath}/beam_fb_unc\"]\n",
    "        fbUnc = list(fbUnc[:])\n",
    "        print(len(fbUnc))\n",
    "\n",
    "        # Read in the ref height index\n",
    "        refSurfIdxs = file[f'/{beamDataPath}/beam_refsurf_ndx']\n",
    "        refSurfIdxs = list(refSurfIdxs[:])\n",
    "        print(len(refSurfIdxs))\n",
    "        \n",
    "        # Read in the height seg index\n",
    "        heightSegIds = file[f'/{beamDataPath}/height_segment_id']\n",
    "        heightSegIds = list(heightSegIds[:])\n",
    "        print(len(heightSegIds))\n",
    "\n",
    "        # Read in along track distance - used to see how far in meters from refSurface\n",
    "        alongTrackDist = file[f'/{beamDataPath}/seg_dist_x']\n",
    "        alongTrackDist = list(alongTrackDist[:])\n",
    "        print(len(alongTrackDist))\n",
    "\n",
    "        refSurfPositions = []\n",
    "        refSurfTypes = []\n",
    "        refSurfMss = []\n",
    "        refSurfHeights = []\n",
    "        refSurfFbUncertainties = []\n",
    "        refSurfStDevs = []\n",
    "        for i in range(len(refSurfIdxs)):\n",
    "            # Index based from 1 for reference surfaces (sea surfaces)\n",
    "            rsIdx = refSurfIdxs[i]-1\n",
    "            pointRefSurfPosition  = refSurfPos[rsIdx]\n",
    "            pointRefSurfType = refSurfType[rsIdx]\n",
    "            pointMss = mss[rsIdx]\n",
    "            pointRefSurfHeight = refSurfHeight[rsIdx]\n",
    "            pointStdDev = refSurfStdDev[rsIdx]\n",
    "            pointUncertainty = refSurfFbUnc[rsIdx]\n",
    "\n",
    "            refSurfPositions.append(pointRefSurfPosition)\n",
    "            refSurfTypes.append(pointRefSurfType)\n",
    "            refSurfMss.append(pointMss)\n",
    "            refSurfHeights.append(pointRefSurfHeight)\n",
    "            refSurfStDevs.append(pointStdDev)\n",
    "            refSurfFbUncertainties.append(pointUncertainty)\n",
    "\n",
    "        heightFlags = []\n",
    "        heightConc = []\n",
    "        heightStdDevs = []\n",
    "        heightSshFlags = []\n",
    "        heightRms = []\n",
    "        heights = []\n",
    "        heightConf = []\n",
    "\n",
    "        print(len(heightSegFlag))\n",
    "        print(len(heightSegIce))\n",
    "        print(len(heightSegStdDev))\n",
    "        print(len(heightSegSshFlag))\n",
    "        print(len(heightSegRms))\n",
    "        print(len(heightSegHeight))\n",
    "        print(len(heightSegConf))\n",
    "\n",
    "        print(\"======\")\n",
    "        print(len(heightSegIds))\n",
    "        print(max(heightSegIds))\n",
    "        print(min(heightSegIds))\n",
    "\n",
    "        for id in heightSegIds:\n",
    "            # Index based from 1 for reference surfaces (sea surfaces)\n",
    "            try:\n",
    "                pointHeightFlags = heightSegFlag[id]\n",
    "                pointHeightConc = heightSegIce[id]\n",
    "                pointHeightStdDevs = heightSegStdDev[id]\n",
    "                pointHeightSshFlags = heightSegSshFlag[id]\n",
    "                pointHeightRms = heightSegRms[id]\n",
    "                pointHeights = heightSegHeight[id]\n",
    "                pointHeightConf = heightSegConf[id]\n",
    "\n",
    "                heightFlags.append(pointHeightFlags)\n",
    "                heightConc.append(pointHeightConc)\n",
    "                heightStdDevs.append(pointHeightStdDevs)\n",
    "                heightSshFlags.append(pointHeightSshFlags)\n",
    "                heightRms.append(pointHeightRms)\n",
    "                heights.append(pointHeights)\n",
    "                heightConf.append(pointHeightConf)\n",
    "\n",
    "            except:\n",
    "                heightFlags.append(\"-\")\n",
    "                heightConc.append(\"-\")\n",
    "                heightStdDevs.append(\"-\")\n",
    "                heightSshFlags.append(\"-\")\n",
    "                heightRms.append(\"-\")\n",
    "                heights.append(\"-\")\n",
    "                heightConf.append(\"-\")\n",
    "\n",
    "        # Calculate ground distance\n",
    "        distance = []\n",
    "        x1 = longitude[0]\n",
    "        y1 = latitude[0]\n",
    "\n",
    "        for i in range(len(latitude)):\n",
    "            x2 = longitude[i]\n",
    "            y2 = latitude[i]\n",
    "            deltaDistance = hs.haversine((y1,x1), (y2, x2), normalize=True, unit=\"m\")\n",
    "            distance.append(deltaDistance)\n",
    "            x1= x2\n",
    "            y1 = y2\n",
    "\n",
    "        # Calculate the times\n",
    "        timevar = file[f'/{beamDataPath}/delta_time']\n",
    "        time = list(timevar[:])\n",
    "        dateTime = []\n",
    "        GPS_EPOCH = datetime.datetime(2018,1,1).timestamp()    # Passing in the ATLAS EPOCH\n",
    "\n",
    "        for timeInSec in time:\n",
    "            calendarTime = datetime.datetime.fromtimestamp(timeInSec+GPS_EPOCH).strftime('\\\"%H:%M:%S.%f %Y-%m-%d\\\"')\n",
    "            dateTime.append(calendarTime)\n",
    "\n",
    "        # We want to append the lat/lon, fbheights, ground distance, refSurfance data for each beam, and then dateTime only on the las\n",
    "\n",
    "        for i in range(len(latitude)):\n",
    "            df_dict['Beam'].append(beam)\n",
    "            df_dict[\"Lat\"].append(latitude[i])\n",
    "            df_dict[\"Lon\"].append(longitude[i])\n",
    "            df_dict[\"FBH\"].append(fbHeight[i])\n",
    "            df_dict[\"FBH Confidence\"].append(fbConf[i])\n",
    "            df_dict[\"FBH Quality\"].append(fbQuality[i])\n",
    "            df_dict[\"FBH Uncertainty\"].append(fbUnc[i])\n",
    "            df_dict[\"Ground Dist(m)\"].append(distance[i])\n",
    "            df_dict[\"Along Track Dist(m)\"].append(alongTrackDist[i])\n",
    "            df_dict[\"RS Index (1-based)\"].append(refSurfIdxs[i])\n",
    "            df_dict[\"RS Pos\"].append(refSurfPositions[i])\n",
    "            df_dict[\"RS Type\"].append(refSurfTypes[i])\n",
    "            df_dict[\"RS Height(m)\"].append(refSurfHeights[i])\n",
    "            df_dict[\"RS FB Uncertainty(m)\"].append(refSurfFbUncertainties[i])\n",
    "            df_dict[\"RS Std Dev\"].append(refSurfStDevs[i])\n",
    "            df_dict[\"RS MSS\"].append(refSurfMss[i])\n",
    "            df_dict[\"Calendar Time\"].append(dateTime[i])\n",
    "            df_dict[\"Height Likely Obstructed\"].append(heightFlags[i])\n",
    "            df_dict[\"Ice Concentration\"].append(heightConc[i])\n",
    "            df_dict[\"Ice Height St Dev\"].append(heightStdDevs[i])\n",
    "            df_dict[\"Ice Surface Flag\"].append(heightSshFlags[i])\n",
    "            df_dict[\"Ice Surface RMS\"].append(heightRms[i])\n",
    "            df_dict[\"Ice Surface Height\"].append(heights[i])\n",
    "            df_dict[\"Ice Surface Conf\"].append(heightConf[i])\n",
    "\n",
    "        for col, data in df_dict.items():\n",
    "            print(beam)\n",
    "            print(f\"{col}:{len(data)}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "                \n",
    "df = pd.DataFrame(dict([(k,pd.Series(v)) for k,v in df_dict.items()]))\n",
    "df = df.replace(r'^\\s*$', np.nan, regex=True)\n",
    "\n",
    "print(df.head(5))\n",
    "print(df.shape)\n",
    "# Drop all rows where ICESAT has no FB height data\n",
    "val = df.iloc[0]['FBH']\n",
    "filtered = df[ df['FBH'] != val ]\n",
    "print(filtered.head(5))\n",
    "print(filtered.shape)\n",
    "\n",
    "\n",
    "filtered.to_csv(out_file, date_format=None)\n",
    "\n",
    "print(\"Wrote to CSV\")\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtered_data = df[((df['Beam'] == \"gt3r\") & (df['Lat'] >= 73.33600090039984) & (df['Lat'] <= 73.49509385766623)) | ((df['Beam'] == \"gt2r\") & (df['Lat'] >= 73.31687496480691) & (df['Lat'] <= 73.47566525356756))]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
