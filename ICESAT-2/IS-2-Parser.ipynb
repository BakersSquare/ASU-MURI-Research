{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Quick visualization of data along a ICESAT2 Track\n",
    "To understand more about the data being input to this script, consider visiting https://nsidc.org/sites/default/files/atl10-v005-userguide_1_0.pdf\n",
    "Code written originally by: Chris Polashenski\n",
    "Refactored, added command line support, and removed sartopy package: John Baker\n",
    "\"\"\"\n",
    "\n",
    "import h5py\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import numpy as np\n",
    "import sys\n",
    "import haversine as hs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_file = \"D:\\\\ICEEYE\\\\Proposal_ID_PP0091278\\\\CS-13801\\\\SLEA_3279211_180312\\\\Baker\\\\Coincident Data\\\\ATL10QL-01_20240119042539_04792201_006_01.h5\"\n",
    "print(in_file)\n",
    "path_parts = in_file.split(\"\\\\\")\n",
    "file_name = path_parts[-1]\n",
    "del path_parts[-1]\n",
    "\n",
    "path_parts.append(file_name[0:-3])\n",
    "out_file = '/'.join(path_parts) + \".csv\"\n",
    "print(out_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(in_file, mode='r') as file:\n",
    "    print(list(file.keys()))\n",
    "    beam_enum = ['gt1r', 'gt1l', 'gt2r', 'gt2l', 'gt3r', 'gt3l']\n",
    "\n",
    "    df_dict = {\n",
    "        'Beam': [],\n",
    "        \"Lat\": [],\n",
    "        \"Lon\": [],\n",
    "        \"FBH\": [],\n",
    "        \"FBH Confidence\": [],\n",
    "        \"FBH Quality\": [],\n",
    "        \"FBH Uncertainty\": [],\n",
    "        \"Ground Dist(m)\": [],\n",
    "        \"Along Track Dist(m)\": [],\n",
    "        \"RS Index (1-based)\": [],\n",
    "        \"RS Pos\": [],\n",
    "        \"RS Type\": [],\n",
    "        \"RS Height(m)\": [],\n",
    "        \"RS FB Uncertainty(m)\": [],\n",
    "        \"RS Std Dev\": [],\n",
    "        \"RS MSS\": [],\n",
    "        \"Calendar Time\": []\n",
    "    }\n",
    "\n",
    "    if \"gt1r/freeboard_beam_segment/beam_freeboard\" in file:\n",
    "        filePathToBeamData = \"freeboard_beam_segment/beam_freeboard\"\n",
    "    else:\n",
    "        filePathToBeamData = \"freeboard_segment\"\n",
    "\n",
    "    if \"gt1r/freeboard_beam_segment/reference_surface_section\" in file:\n",
    "        filePathToReferenceHeights = \"freeboard_beam_segment/reference_surface_section\"\n",
    "    else:\n",
    "        filePathToReferenceHeights = \"reference_surface_section\"\n",
    "\n",
    "    print(filePathToBeamData)\n",
    "    print(filePathToReferenceHeights)\n",
    "\n",
    "    for beam in beam_enum:\n",
    "        beamDataPath = f\"{beam}/{filePathToBeamData}\"\n",
    "        refDataPath = f\"{beam}/{filePathToReferenceHeights}\"\n",
    "        ############################### Store the reference surface data ########################################\n",
    "        # Read in the distance from the reference surface to the equator\n",
    "        refSurfPos = file[f'/{refDataPath}/beam_refsurf_dist_x']\n",
    "        refSurfPos = list(refSurfPos[:])\n",
    "\n",
    "        # Read in the interpolation flag of the reference surface\n",
    "        refSurfType = file[f\"/{refDataPath}/beam_refsurf_interp_flag\"]\n",
    "        refSurfType = list(refSurfType[:])\n",
    "\n",
    "        # Read in the uncertainty propogating to the freeboard, based on the reference surface estimate\n",
    "        refSurfFbUnc = file[f\"/{refDataPath}/beam_fb_unc_refsurf\"]\n",
    "        refSurfFbUnc = list(refSurfFbUnc[:])\n",
    "\n",
    "        # Read in mean sea surface height (the base elevation everything is referring to)\n",
    "        mss = file[f\"/{refDataPath}/beam_refsurf_mss\"]\n",
    "        mss = list(mss[:])\n",
    "\n",
    "        # Read in the inferred ice elevation (the base elevation for the snow is referring to)\n",
    "        refSurfHeight = file[f\"/{refDataPath}/beam_refsurf_height\"]\n",
    "        refSurfHeight = list(refSurfHeight[:])\n",
    "\n",
    "        # Read in the standard deviation of the refsurf height\n",
    "        refSurfStdDev = file[f'/{refDataPath}/beam_refsurf_sigma']\n",
    "        refSurfStdDev = list(refSurfStdDev[:])\n",
    "        #######################################################################      \n",
    "\n",
    "        # Read in the lat/lon\n",
    "        latitude = file[f'/{beamDataPath}/latitude']\n",
    "        latitude = list(latitude[:])\n",
    "        longitude = file[f'/{beamDataPath}/longitude']\n",
    "        longitude = list(longitude[:])\n",
    "\n",
    "        # Read in the freeboard height\n",
    "        fbHeight = file[f'/{beamDataPath}/beam_fb_height']\n",
    "        fbHeight = list(fbHeight[:])\n",
    "\n",
    "        # Read in the fbh confidence\n",
    "        fbConf = file[f'/{beamDataPath}/beam_fb_confidence']\n",
    "        fbConf = list(fbConf[:])\n",
    "\n",
    "        # Read in the quality flag\n",
    "        fbQuality = file[f\"/{beamDataPath}/beam_fb_quality_flag\"]\n",
    "        fbQuality = list(fbQuality[:])\n",
    "\n",
    "        # Read in the total uncertainty from the refSurf + height\n",
    "        fbUnc = file[f\"/{beamDataPath}/beam_fb_unc\"]\n",
    "        fbUnc = list(fbUnc[:])\n",
    "\n",
    "        # Read in the ref height index\n",
    "        refSurfIdxs = file[f'/{beamDataPath}/beam_refsurf_ndx']\n",
    "        refSurfIdxs = list(refSurfIdxs[:])\n",
    "\n",
    "        # Read in along track distance - used to see how far in meters from refSurface\n",
    "        alongTrackDist = file[f'/{beamDataPath}/seg_dist_x']\n",
    "        alongTrackDist = list(alongTrackDist[:])\n",
    "\n",
    "        refSurfPositions = []\n",
    "        refSurfTypes = []\n",
    "        refSurfMss = []\n",
    "        refSurfHeights = []\n",
    "        refSurfFbUncertainties = []\n",
    "        refSurfStDevs = []\n",
    "        for i in range(len(refSurfIdxs)):\n",
    "            rsIdx = refSurfIdxs[i]-1\n",
    "            pointRefSurfPosition  = refSurfPos[rsIdx]\n",
    "            pointRefSurfType = refSurfType[rsIdx]\n",
    "            pointMss = mss[rsIdx]\n",
    "            pointRefSurfHeight = refSurfHeight[rsIdx]\n",
    "            pointStdDev = refSurfStdDev[rsIdx]\n",
    "            pointUncertainty = refSurfFbUnc[rsIdx]\n",
    "\n",
    "            refSurfPositions.append(pointRefSurfPosition)\n",
    "            refSurfTypes.append(pointRefSurfType)\n",
    "            refSurfMss.append(pointMss)\n",
    "            refSurfHeights.append(pointRefSurfHeight)\n",
    "            refSurfStDevs.append(pointStdDev)\n",
    "            refSurfFbUncertainties.append(pointUncertainty)\n",
    "\n",
    "        # print(\"Max refSurf Idx: \", max(refSurfIdxs))\n",
    "        # print(\"Min refSurf Idx: \", min(refSurfIdxs))\n",
    "\n",
    "        # Calculate ground distance\n",
    "        distance = []\n",
    "        x1 = longitude[0]\n",
    "        y1 = latitude[0]\n",
    "\n",
    "        for i in range(len(latitude)):\n",
    "            x2 = longitude[i]\n",
    "            y2 = latitude[i]\n",
    "            deltaDistance = hs.haversine((y1,x1), (y2, x2), normalize=True, unit=\"m\")\n",
    "            distance.append(deltaDistance)\n",
    "            x1= x2\n",
    "            y1 = y2\n",
    "\n",
    "        # Calculate the times\n",
    "        timevar = file[f'/{beamDataPath}/delta_time']\n",
    "        time = list(timevar[:])\n",
    "        dateTime = []\n",
    "        GPS_EPOCH = datetime.datetime(2018,1,1).timestamp()    # Passing in the ATLAS EPOCH\n",
    "\n",
    "        for timeInSec in time:\n",
    "            calendarTime = datetime.datetime.fromtimestamp(timeInSec+GPS_EPOCH).strftime('\\\"%H:%M:%S.%f %Y-%m-%d\\\"')\n",
    "            dateTime.append(calendarTime)\n",
    "\n",
    "        # We want to append the lat/lon, fbheights, ground distance, refSurfance data for each beam, and then dateTime only on the las\n",
    "\n",
    "        for i in range(len(latitude)):\n",
    "            df_dict['Beam'].append(beam)\n",
    "            df_dict[\"Lat\"].append(latitude[i])\n",
    "            df_dict[\"Lon\"].append(longitude[i])\n",
    "            df_dict[\"FBH\"].append(fbHeight[i])\n",
    "            df_dict[\"FBH Confidence\"].append(fbConf[i])\n",
    "            df_dict[\"FBH Quality\"].append(fbQuality[i])\n",
    "            df_dict[\"FBH Uncertainty\"].append(fbUnc[i])\n",
    "            df_dict[\"Ground Dist(m)\"].append(distance[i])\n",
    "            df_dict[\"Along Track Dist(m)\"].append(alongTrackDist[i])\n",
    "            df_dict[\"RS Index (1-based)\"].append(refSurfIdxs[i])\n",
    "            df_dict[\"RS Pos\"].append(refSurfPositions[i])\n",
    "            df_dict[\"RS Type\"].append(refSurfTypes[i])\n",
    "            df_dict[\"RS Height(m)\"].append(refSurfHeights[i])\n",
    "            df_dict[\"RS FB Uncertainty(m)\"].append(refSurfFbUncertainties[i])\n",
    "            df_dict[\"RS Std Dev\"].append(refSurfStDevs[i])\n",
    "            df_dict[\"RS MSS\"].append(refSurfMss[i])\n",
    "            df_dict[\"Calendar Time\"].append(dateTime[i])\n",
    "\n",
    "        for col, data in df_dict.items():\n",
    "            print(beam)\n",
    "            print(f\"{col}:{len(data)}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "                \n",
    "df = pd.DataFrame(dict([(k,pd.Series(v)) for k,v in df_dict.items()]))\n",
    "df = df.replace(r'^\\s*$', np.nan, regex=True)\n",
    "\n",
    "print(df.head(5))\n",
    "print(df.shape)\n",
    "# Drop all rows where ICESAT has no FB height data\n",
    "val = df.iloc[0]['FBH']\n",
    "filtered = df[ df['FBH'] != val ]\n",
    "print(filtered.head(5))\n",
    "print(filtered.shape)\n",
    "\n",
    "\n",
    "filtered.to_csv(out_file, date_format=None)\n",
    "\n",
    "print(\"Wrote to CSV\")\n",
    "print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
