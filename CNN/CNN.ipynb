{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Packages and Defining Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used to get statistics for preprocessing\n",
    "from osgeo import gdal\n",
    "\n",
    "\n",
    "# import torch and other necessary modules from torch\n",
    "# https://docs.google.com/document/d/1e3Ybe0KQFmSzbsqRl8o9f-PeWsv5nUrKLBrTgH-Ywsc/edit\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# import torchvision and other necessary modules from torchvision \n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.figure as figure\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "import math\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Helper Functions / Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants to use later in the script\n",
    "PATH_TO_TILED_IMGS = \"D:\\Sentinel1\\six-beam-directory\"\n",
    "SAR_REF = \"./src/data/sentinel2/reprojectedWSG84.tiff\"\n",
    "BATCH_SIZE = 32            # How many random sampled tiles to pull for each iteration of training\n",
    "\n",
    "# Label parser used when previewing the input data \n",
    "def parseLabel(filename: str):\n",
    "    index, file = filename.split(\"-\")\n",
    "    basename = file.replace(\".tiff\", \"\")\n",
    "    return (index, basename)\n",
    "\n",
    "# Custom tiled dataset class\n",
    "class SARTile(Dataset):\n",
    "    def __init__(self, data_dir, transform=None):\n",
    "        self.data_dir = data_dir\n",
    "        self.image_list = os.listdir(data_dir)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_name = self.image_list[idx]\n",
    "        image_path = os.path.join(self.data_dir, image_name)\n",
    "        image = Image.open(image_path)\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        index, image_name = parseLabel(image_name)\n",
    "            \n",
    "        return (image, float(image_name), index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading Data + Setting Preprocessing Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference to the SAR image that our dataset was tiled from\n",
    "SAR = gdal.Open(SAR_REF)\n",
    "\n",
    "# Calculating the global stats of the file to preprocess our tiles\n",
    "tiffMin, tiffMax, tiffMean, tiffStDev = SAR.GetRasterBand(1).GetStatistics(0,1)\n",
    "\n",
    "# IceSat beam data. Note: Labeling was done in the tiling script, this reading is just for stats.\n",
    "beam_data = pd.read_csv(\"./src/data/icesat2/3BeamCoordinates+Extra.csv\")\n",
    "fbh_mean = beam_data[['gt1rFBH', 'gt1lFBH', 'gt2rFBH', 'gt2lFBH', 'gt3rFBH', 'gt3lFBH']].mean()         # Calculates the mean beam measure of each laser\n",
    "fbh_mean = fbh_mean.mean()                                                                              # Calculates the mean of means\n",
    "beam_data = None                                                                                        # Closes the df\n",
    "\n",
    "# Defining the images as grayscale, converting it to a tensor, adding random flips and rotations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1), # We know the inputs are greyscale\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomVerticalFlip(p=0.5),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=tiffMean,\n",
    "        std=tiffStDev\n",
    "    )\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Read Data and set Train/Test splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading in the dataset using the custom class defined above\n",
    "dataset = SARTile(data_dir = PATH_TO_TILED_IMGS, transform=transform)\n",
    "\n",
    "# 80/20 split of train/test \n",
    "train_size = int(len(dataset) * 0.8)\n",
    "test_size = len(dataset) - train_size\n",
    "print(train_size)\n",
    "print(test_size)\n",
    "train_set, test_set = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "\n",
    "# prepare dataloader for training set and evaluation set\n",
    "trainloader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True)\n",
    "testloader = DataLoader(test_set, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "# Visualizing some of the testing data\n",
    "fig, axs = plt.subplots(5, 3, figsize=(8,8))\n",
    "i = 0\n",
    "for ax in axs.flat:\n",
    "    img, label, index = train_set[i]\n",
    "    ax.set_title(index)\n",
    "    ax.set_xlabel(label)\n",
    "    ax.set_ylabel(\"\")\n",
    "    ax.tick_params(which=\"both\", length=0, width=0, labelsize=0)\n",
    "    ax.imshow(img.squeeze()) #cmap=\"gray\"\n",
    "    i += 1\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Architecture\n",
    "Ideas to toy with:  \n",
    "&emsp;1 Analyzing pattern of speckle (should avoid pooling and rely instead on convolutions)  \n",
    "&emsp;2 Analyze brightness of values (would likely need to pool, because we agree we should hold weight here)       \n",
    "&emsp;3 More outchannels lets the model potentially learn more from the feature  \n",
    "&emsp;&emsp;- https://stackoverflow.com/questions/56652204/pytorch-convolution-in-channels-and-out-channels-meaning  \n",
    "&emsp;4 Batch norming?  \n",
    "&emsp;5 Dropout?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN,self).__init__()\n",
    "\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 16, 3, dilation=2) # 1 channel, outputting 16 channels, kernel size of 3 with dilation\n",
    "        self.conv2 = nn.Conv2d(16, 32, 3) # 16 channels, doubling to 32 with a kernel size 5\n",
    "        \n",
    "        self.avgPool = nn.AvgPool2d(2,2)\n",
    "        self.maxPool = nn.MaxPool2d(2,2)\n",
    "\n",
    "        # Consider using global averaging for these outputs instead of all fully connected layers\n",
    "        self.fc1 = nn.Linear(128, 64)\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.fc3 = nn.Linear(32, 1)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Convolve, rectify, maxpool\n",
    "        x = self.maxPool(F.relu(self.conv1(x)))\n",
    "        \n",
    "        # Insert batch norm between convolutions here\n",
    "\n",
    "        # Convolve, rectify, maxpool\n",
    "        x = self.maxPool(F.relu(self.conv2(x)))\n",
    "        \n",
    "        # Flatten\n",
    "        x = torch.flatten(x, 1) # flatten\n",
    "        \n",
    "        # Send to fully connected layers\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        \n",
    "        # Flatten down to 1 value, and return it's tensor\n",
    "        x = self.fc3(x)\n",
    "        return x.flatten()\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu' # whether your device has GPU\n",
    "print(device)\n",
    "cnn = CNN().to(device) # move the model to GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### HELPER FUNCTION FOR FEATURE EXTRACTION (ty to https://kozodoi.me/blog/20210527/extracting-features)\n",
    "# placeholders\n",
    "INPUTS = []\n",
    "OUTPUTS = []\n",
    "C1_FEATS = []\n",
    "C2_FEATS = []\n",
    "\n",
    "# placeholder for batch features\n",
    "features = {}\n",
    "\n",
    "def get_features(name):\n",
    "    def hook(model, input, output):\n",
    "        features[name] = output.detach()\n",
    "    return hook\n",
    "\n",
    "cnn.conv1.register_forward_hook(get_features('conv1'))\n",
    "cnn.conv2.register_forward_hook(get_features('conv2'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the training weights whenever we run the training again\n",
    "for layer in cnn.children():\n",
    "   if hasattr(layer, 'reset_parameters'):\n",
    "       layer.reset_parameters()\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "# try Adam optimizer (https://pytorch.org/docs/stable/generated/torch.optim.Adam.html) with learning rate 0.0001, feel free to use other optimizer\n",
    "optimizer = torch.optim.Adam(cnn.parameters(), lr=.0001)\n",
    "\n",
    "# Training\n",
    "# model hyperparameter\n",
    "learning_rate = 0.001\n",
    "epoch_size = 5\n",
    "\n",
    "loss_arr = []\n",
    "cnn.train() # turn on train mode, this is a good practice to do\n",
    "for epoch in range(epoch_size): # begin with trying 10 epochs \n",
    "\n",
    "    loss = 0.0 \n",
    "    running_loss = 0.0 # you can print out average loss per batch every certain batches\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs and label from dataloader\n",
    "        inputs, labels, _ = data\n",
    "        \n",
    "        # Convert the float values into long\n",
    "        labels = labels.float()\n",
    "        \n",
    "        # move tensors to your current device (cpu or gpu)\n",
    "        INPUTS.append(inputs.numpy())\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # zero the parameter gradients using zero_grad()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward -> compute loss -> backward propogation -> optimize (see tutorial mentioned in main documentation)\n",
    "        outputs = cnn(inputs)\n",
    "\n",
    "        # add feats and outputs to lists\n",
    "        OUTPUTS.append(outputs.detach().cpu().numpy())\n",
    "        C1_FEATS.append(features['conv1'].cpu().numpy())\n",
    "        C2_FEATS.append(features['conv2'].cpu().numpy())\n",
    "\n",
    "        curLoss = criterion(outputs, labels)\n",
    "        curLoss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print some statistics\n",
    "        loss =  curLoss.item()\n",
    "        if i == 0 and epoch == 0:\n",
    "            print(loss)\n",
    "        running_loss += loss\n",
    "        if i % 10 == 9:    # print out average loss every 100 batches\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / i:.3f}')\n",
    "\n",
    "        # We can add an early stop condition here\n",
    "        # if _____:\n",
    "        #    break\n",
    "    loss_arr.append(running_loss / len(trainloader))\n",
    "            \n",
    "OUTPUTS = np.concatenate(OUTPUTS)\n",
    "C1_FEATS = np.concatenate(C1_FEATS)\n",
    "C2_FEATS = np.concatenate(C2_FEATS)\n",
    "\n",
    "plt.plot(loss_arr, label='Training Loss')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('- outputs shape:', OUTPUTS.shape)\n",
    "print('- c1 feats shape:', C1_FEATS.shape)\n",
    "print('- c2 feats shape:', C2_FEATS.shape)\n",
    "\n",
    "\n",
    "print(len(features['conv1'][0]))\n",
    "print(len(features['conv2'][0]))\n",
    "\n",
    "first_input_c1 = C1_FEATS[0]          # This is a dictionary of all inputs passed through our first convolution. This gets the first one\n",
    "first_input_c2 = C2_FEATS[0]          # This is a dictionary of all inputs passed through our second convolution. This gets the first one\n",
    "print(len(first_input_c1))\n",
    "print(len(first_input_c2))\n",
    "\n",
    "\n",
    "num_feat_maps_c1 = first_input_c1.shape[0]  # Conv 1 results in 16 feature maps of size 13x13\n",
    "sub_graph_dim_c1 = math.ceil(math.sqrt(num_feat_maps_c1))\n",
    "\n",
    "num_feat_maps_c2 = first_input_c2.shape[0]  # Conv 2 results in 16 feature maps of size 13x13\n",
    "sub_graph_dim_c2 = math.ceil(math.sqrt(num_feat_maps_c2))\n",
    "\n",
    "\n",
    "print(INPUTS[0].shape)       # 430 (training iterations) x 128 (batch size) x (1 channel x 17px x 17px)\n",
    "plt.imshow(INPUTS[0][0][0])#, interpolation=\"spline16\")\n",
    "\n",
    "# using the variable axs for multiple Axes\n",
    "fig, ax = plt.subplots(sub_graph_dim_c1, sub_graph_dim_c1)\n",
    "fig.tight_layout()\n",
    "count = 0\n",
    "for i, x in enumerate(ax):\n",
    "    for j, y in enumerate(x):\n",
    "        ax[i, j].imshow(first_input_c1[count])#, interpolation=\"spline16\")\n",
    "        # ax[i, j].set_axis_off()\n",
    "        ax[i, j].set_title(f'Feat Map {count}')\n",
    "        count = count + 1\n",
    "\n",
    "fig, ax = plt.subplots(sub_graph_dim_c2, sub_graph_dim_c2)\n",
    "fig.tight_layout()\n",
    "count = 0\n",
    "for i, x in enumerate(ax):\n",
    "    for j, y in enumerate(x):\n",
    "        if(count < len(first_input_c2)):\n",
    "            ax[i, j].imshow(first_input_c2[count])#, interpolation=\"spline16\")\n",
    "            ax[i, j].set_axis_off()\n",
    "            ax[i, j].set_title(f'Feat Map {count}')\n",
    "            count = count + 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation on evaluation set\n",
    "ground_truth = []\n",
    "prediction = []\n",
    "cnn.eval() # turn on evaluation model, also a good practice to do\n",
    "\n",
    "cnn.train(mode=False)\n",
    "with torch.no_grad(): # since we're not training, we don't need to calculate the gradients for our outputs, so turn on no_grad mode\n",
    "    for i, data in enumerate(testloader, 0):\n",
    "        inputs, labels, _ = data\n",
    "        inputs = inputs.to(device)\n",
    "        ground_truth += list(labels)    # convert labels to list and append to ground_truth\n",
    "        # calculate outputs by running inputs through the network\n",
    "        outputs = cnn(inputs)\n",
    "        predicted = outputs.detach().cpu().flatten()\n",
    "#         print(predicted.tolist())\n",
    "        prediction.extend(predicted.tolist()),\n",
    "\n",
    "totErr = 0\n",
    "for i in range(len(ground_truth)):\n",
    "    err = ground_truth[i].item() - prediction[i]\n",
    "    totErr += err\n",
    "    if i % 10 == 0:\n",
    "        print(f\"==={i}==\")\n",
    "        print(f\"Actual: {ground_truth[i]}\")\n",
    "        print(f\"Predicted: {prediction[i]}\")\n",
    "        print(f\"Diff: {err}\")\n",
    "\n",
    "print(f\"Cumulative err: {totErr}\")\n",
    "print(\"=============\")\n",
    "r2score = r2_score(y_true=ground_truth, y_pred=prediction)\n",
    "mse = mean_squared_error(y_true=ground_truth, y_pred=prediction)\n",
    "rmse = math.sqrt(mse)\n",
    "n_rmse = rmse / (max(ground_truth) - min(ground_truth))\n",
    "print(f\"R2: {r2score}\")\n",
    "print(f\"MSE: {mse}\")\n",
    "print(f\"RMSE: {rmse}\")\n",
    "print(f\"NORM RMSE: {n_rmse}\")\n",
    "\n",
    "\n",
    "ground_truth_nums = [x.item() for x in ground_truth]\n",
    "# print(ground_truth_nums)\n",
    "plt.plot(ground_truth_nums, prediction, 'ro')\n",
    "plt.xlabel('Actual values')\n",
    "plt.ylabel('Predicted values')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
